{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flood Risk Forecasting with LSTM\n",
        "This notebook demonstrates how to fetch hydrological data, train an LSTM model to predict streamflow, and derive flood risk alerts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from flood_risk.data_fetch import (USGSConfig, NOAAConfig, fetch_noaa_precipitation, fetch_usgs_streamflow, merge_hydro_meteorological, create_supervised_sequences)\n",
        "from flood_risk.preprocess import TimeSeriesScaler, train_val_test_split, compute_risk_score\n",
        "from flood_risk.model import LSTMForecaster\n",
        "from flood_risk.training import TrainingConfig, create_dataloader, train_model, iter_predictions\n",
        "from flood_risk.alerting import evaluate_risk\n",
        "plt.style.use('seaborn-v0_8')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "Adjust the identifiers and lookback horizon for your region of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SITE_ID = '07289000'  # example: Mississippi River at Vicksburg\n",
        "STATION_ID = 'GHCND:USW00012916'  # example: New Orleans International Airport\n",
        "START_DATE = dt.date(2020, 1, 1)\n",
        "END_DATE = dt.date(2020, 12, 31)\n",
        "LOOKBACK = 30\n",
        "HORIZON = 7\n",
        "RISK_THRESHOLD = 200000  # cubic feet per second\n",
        "NOAA_TOKEN = os.getenv('NOAA_TOKEN')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Ingestion\n",
        "The cell below attempts to download live data. If the APIs are unavailable, synthetic data is generated to illustrate the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "data"
        ]
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    usgs_cfg = USGSConfig(site=SITE_ID, start_date=START_DATE, end_date=END_DATE)\n",
        "    noaa_cfg = NOAAConfig(station=STATION_ID, start_date=START_DATE, end_date=END_DATE)\n",
        "    streamflow = fetch_usgs_streamflow(usgs_cfg)\n",
        "    precip = fetch_noaa_precipitation(noaa_cfg, token=NOAA_TOKEN)\n",
        "    data = merge_hydro_meteorological(streamflow, precip, freq='D')\n",
        "    source_label = 'USGS/NOAA API'\n",
        "except Exception as exc:\n",
        "    print(f'Falling back to synthetic data because: {exc}')\n",
        "    index = pd.date_range(START_DATE, END_DATE, freq='D')\n",
        "    discharge = 150000 + 40000 * np.sin(np.linspace(0, 12 * np.pi, len(index)))\n",
        "    precip = 10 * np.maximum(0, np.random.randn(len(index)))\n",
        "    data = pd.DataFrame({'discharge_cfs': discharge, 'precip_mm': precip}, index=index)\n",
        "    source_label = 'synthetic generator'\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "Convert the daily time series into rolling windows for LSTM training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_seq, y_seq = create_supervised_sequences(data, target_col='discharge_cfs', lookback=LOOKBACK, horizon=HORIZON)\n",
        "X = np.stack(x_seq.values)\n",
        "y = np.stack(y_seq.values)\n",
        "scaler = TimeSeriesScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_min = y.min()\n",
        "y_max = y.max()\n",
        "y_scaled = (y - y_min) / (y_max - y_min)\n",
        "(train, val, test) = train_val_test_split(X_scaled, y_scaled)\n",
        "len(train[0]), len(val[0]), len(test[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "Instantiate the LSTM forecaster and train with early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "input_size = X.shape[2]\n",
        "model = LSTMForecaster(input_size=input_size, hidden_size=64, num_layers=2, horizon=HORIZON)\n",
        "config = TrainingConfig(epochs=30, learning_rate=1e-3, batch_size=32, patience=5, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = create_dataloader(train[0], train[1], batch_size=config.batch_size, shuffle=True)\n",
        "val_loader = create_dataloader(val[0], val[1], batch_size=config.batch_size, shuffle=False)\n",
        "history = train_model(model, train_loader, val_loader, config)\n",
        "history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "plot"
        ]
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history['train_loss'], label='Train')\n",
        "plt.plot(history['val_loss'], label='Validation')\n",
        "plt.title('Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "Generate predictions for the holdout set and compare with actual discharge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loader = create_dataloader(test[0], test[1], batch_size=config.batch_size, shuffle=False)\n",
        "device = torch.device(config.device)\n",
        "pred_batches = list(iter_predictions(model, test_loader, device))\n",
        "predictions_scaled = np.concatenate(pred_batches, axis=0)\n",
        "predictions = predictions_scaled * (y_max - y_min) + y_min\n",
        "actuals = test[1] * (y_max - y_min) + y_min\n",
        "pred_series = pd.Series(predictions[:, 0], index=data.index[-len(predictions):])\n",
        "actual_series = pd.Series(actuals[:, 0], index=data.index[-len(actuals):])\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(actual_series, label='Observed')\n",
        "plt.plot(pred_series, label='Forecasted')\n",
        "plt.title(f'Streamflow forecast comparison ({source_label})')\n",
        "plt.ylabel('Discharge (cfs)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flood Risk Assessment\n",
        "Calculate risk scores relative to a discharge threshold and inspect exceedance days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_series = compute_risk_score(pred_series, threshold=RISK_THRESHOLD)\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.plot(risk_series, label='Risk score')\n",
        "plt.axhline(1.0, color='red', linestyle='--', label='Alert threshold')\n",
        "plt.ylabel('Risk Ratio')\n",
        "plt.title('Flood risk ratio over forecast horizon')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "risk_series.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alert Simulation\n",
        "Use the alerting utilities to determine whether an AWS notification should be sent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "peak_predictions = predictions[:, 0]\n",
        "risk_score = evaluate_risk(peak_predictions, threshold=RISK_THRESHOLD)\n",
        "if risk_score >= 1.0:\n",
        "    print(f'ALERT: Risk score {risk_score:.2f} exceeds threshold!')\n",
        "else:\n",
        "    print(f'No alert. Risk score {risk_score:.2f}.')\n",
        "risk_score\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}